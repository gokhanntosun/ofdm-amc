{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data from ofdm dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from comm.OFDM import OFDM\n",
    "\n",
    "BASE = '/Users/gtosun/Documents/vsc_workspace/ofdm-amc/data/data_lib'\n",
    "plt.style.use(style='dark_background')\n",
    "\n",
    "xpaths, ypaths = [], [],\n",
    "for root, _, files in os.walk(BASE):\n",
    "    for file in files:\n",
    "        if file == 'x.npy': xpaths.append(os.path.join(root, file))\n",
    "        if file == 'y.npy': ypaths.append(os.path.join(root, file))\n",
    "\n",
    "d = defaultdict(lambda: defaultdict(dict))\n",
    "for xp, yp in zip(sorted(xpaths), sorted(ypaths)):\n",
    "\n",
    "    tmp = xp.split('/')\n",
    "    mod = tmp[9]\n",
    "    m = tmp[10]\n",
    "    size = tmp[11]\n",
    "\n",
    "    d[f'{m}{mod}'][size]['x'] = np.load(xp)\n",
    "    d[f'{m}{mod}'][size]['y'] = np.load(yp)\n",
    "\n",
    "frame = d['16qam']['512point']['x'][:, :, 999]\n",
    "windows = [256, 512, 1024]\n",
    "\n",
    "filter_bank = [OFDM(n_carriers=n) for n in windows]\n",
    "t_signals = [filter.demodulate(frame) for filter in filter_bank]\n",
    "fig, axs  = plt.subplots(len(t_signals), 1)\n",
    "\n",
    "for ax, t in zip(axs, t_signals):\n",
    "    ax.step(range(len(t[0,:])), t[0,:])\n",
    "    ax.set_xlim(left=0, right=512)\n",
    "    ax.set_ylim(bottom=-3, top=3)\n",
    "    ax.grid(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot constellations from dataset \n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "\n",
    "BASE = '/Users/gtosun/Documents/vsc_workspace/modulation-classification/data/categorical/24db'\n",
    "plt.style.use(style='dark_background')\n",
    "\n",
    "xpaths, ypaths = [], [],\n",
    "for root, _, files in os.walk(BASE):\n",
    "    for file in files:\n",
    "        if file == 'x.npy': xpaths.append(os.path.join(root, file))\n",
    "        if file == 'y.npy': ypaths.append(os.path.join(root, file))\n",
    "\n",
    "d = defaultdict(lambda: dict())\n",
    "for xp, yp in zip(sorted(xpaths), sorted(ypaths)):\n",
    "\n",
    "    tmp = xp.split('/')\n",
    "    m = tmp[-2]\n",
    "    mod = tmp[-3]\n",
    "\n",
    "    d[f'{m}{mod}']['x'] = np.load(xp)\n",
    "    d[f'{m}{mod}']['y'] = np.load(yp)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(style='dark_background')\n",
    "mods = [\"2psk\", \"4psk\", \"4qam\", \"8psk\", \"16qam\", \"16psk\", \"64qam\"]\n",
    "label_dict = {i: mod for i, mod in enumerate(mods)}\n",
    "\n",
    "ks = list(d.keys())\n",
    "num_types = len(ks)\n",
    "\n",
    "nrows = 2\n",
    "ncols = 4\n",
    "\n",
    "fig, axs = plt.subplots(nrows=nrows, ncols=ncols)\n",
    "for i in range(nrows):\n",
    "    for j in range(ncols):\n",
    "\n",
    "        idx = i * ncols + j\n",
    "        if idx >= num_types:\n",
    "            fig.delaxes(axs[i][j])\n",
    "            break\n",
    "\n",
    "        k = ks[idx]\n",
    "\n",
    "        x = d[k]['x'][0, :, :]\n",
    "        xi, xq = x[0, :], x[1, :]\n",
    "\n",
    "        y = d[k]['y'][0]\n",
    "        _, idx = torch.max(torch.squeeze(torch.Tensor(d[k]['y'][0])), 0)\n",
    "    \n",
    "        axs[i][j].set_title(label_dict[idx.item()])\n",
    "        axs[i][j].scatter(xi, xq, marker='s', s=0.75, c='c')\n",
    "        axs[i][j].set_xlim(left=-1.5, right=1.5)\n",
    "        axs[i][j].set_ylim(bottom=-1.5, top=1.5)\n",
    "        axs[i][j].set_aspect('equal')\n",
    "        axs[i][j].margins(0)\n",
    "        axs[i][j].grid(True)\n",
    "\n",
    "fig.set_size_inches(w=ncols * 2, h=nrows * 2)\n",
    "fig.suptitle('constellations')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try torch.stft and torch.istft here \n",
    "import torch\n",
    "\n",
    "def transform(x, n: int):\n",
    "    tmp = torch.stft(input=x, n_fft=n, hop_length=n, center=True, normalized=True, onesided=False, return_complex=True)\n",
    "    tmp = torch.reshape(tmp, (1, tmp.numel()))\n",
    "    return torch.row_stack((torch.real(tmp), torch.imag(tmp)))\n",
    "\n",
    "complex_frame = torch.from_numpy( frame[0, :] + 1j * frame[1, :] )\n",
    "u = [transform(complex_frame, n) for n in windows]\n",
    "\n",
    "fig, axs  = plt.subplots(len(u), 1)\n",
    "for ax, t in zip(axs, u):\n",
    "    ax.step(range(len(t[1,:])), t[1,:])\n",
    "    ax.set_xlim(left=0, right=64)\n",
    "    ax.set_ylim(bottom=-3, top=3)\n",
    "    ax.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gtosun/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Step [100/7650], Loss: 1.1984\n",
      "Epoch [1/1], Step [200/7650], Loss: 1.1464\n",
      "Epoch [1/1], Step [300/7650], Loss: 1.1254\n",
      "Epoch [1/1], Step [400/7650], Loss: 1.1060\n",
      "Epoch [1/1], Step [500/7650], Loss: 1.0872\n",
      "Epoch [1/1], Step [600/7650], Loss: 1.1013\n",
      "Epoch [1/1], Step [700/7650], Loss: 1.0805\n",
      "Epoch [1/1], Step [800/7650], Loss: 1.0596\n",
      "Epoch [1/1], Step [900/7650], Loss: 1.0089\n",
      "Epoch [1/1], Step [1000/7650], Loss: 1.0275\n",
      "Epoch [1/1], Step [1100/7650], Loss: 0.9669\n",
      "Epoch [1/1], Step [1200/7650], Loss: 0.8160\n",
      "Epoch [1/1], Step [1300/7650], Loss: 0.6573\n",
      "Epoch [1/1], Step [1400/7650], Loss: 0.6114\n",
      "Epoch [1/1], Step [1500/7650], Loss: 0.5391\n",
      "Epoch [1/1], Step [1600/7650], Loss: 0.4004\n",
      "Epoch [1/1], Step [1700/7650], Loss: 0.2901\n",
      "Epoch [1/1], Step [1800/7650], Loss: 0.3792\n",
      "Epoch [1/1], Step [1900/7650], Loss: 0.2410\n",
      "Epoch [1/1], Step [2000/7650], Loss: 0.3276\n",
      "Epoch [1/1], Step [2100/7650], Loss: 0.3718\n",
      "Epoch [1/1], Step [2200/7650], Loss: 0.2233\n",
      "Epoch [1/1], Step [2300/7650], Loss: 0.1835\n",
      "Epoch [1/1], Step [2400/7650], Loss: 0.3423\n",
      "Epoch [1/1], Step [2500/7650], Loss: 0.1960\n",
      "Epoch [1/1], Step [2600/7650], Loss: 0.1479\n",
      "Epoch [1/1], Step [2700/7650], Loss: 0.1888\n",
      "Epoch [1/1], Step [2800/7650], Loss: 0.1787\n",
      "Epoch [1/1], Step [2900/7650], Loss: 0.2991\n",
      "Epoch [1/1], Step [3000/7650], Loss: 0.1628\n",
      "Epoch [1/1], Step [3100/7650], Loss: 0.2058\n",
      "Epoch [1/1], Step [3200/7650], Loss: 0.0877\n",
      "Epoch [1/1], Step [3300/7650], Loss: 0.1321\n",
      "Epoch [1/1], Step [3400/7650], Loss: 0.1560\n",
      "Epoch [1/1], Step [3500/7650], Loss: 0.0837\n",
      "Epoch [1/1], Step [3600/7650], Loss: 0.1044\n",
      "Epoch [1/1], Step [3700/7650], Loss: 0.0395\n",
      "Epoch [1/1], Step [3800/7650], Loss: 0.0308\n",
      "Epoch [1/1], Step [3900/7650], Loss: 0.0363\n",
      "Epoch [1/1], Step [4000/7650], Loss: 0.2385\n",
      "Epoch [1/1], Step [4100/7650], Loss: 0.0167\n",
      "Epoch [1/1], Step [4200/7650], Loss: 0.3508\n",
      "Epoch [1/1], Step [4300/7650], Loss: 0.1812\n",
      "Epoch [1/1], Step [4400/7650], Loss: 0.0333\n",
      "Epoch [1/1], Step [4500/7650], Loss: 0.0278\n",
      "Epoch [1/1], Step [4600/7650], Loss: 0.0350\n",
      "Epoch [1/1], Step [4700/7650], Loss: 0.0228\n",
      "Epoch [1/1], Step [4800/7650], Loss: 0.0303\n",
      "Epoch [1/1], Step [4900/7650], Loss: 0.0088\n",
      "Epoch [1/1], Step [5000/7650], Loss: 0.0268\n",
      "Epoch [1/1], Step [5100/7650], Loss: 0.1178\n",
      "Epoch [1/1], Step [5200/7650], Loss: 0.0108\n",
      "Epoch [1/1], Step [5300/7650], Loss: 0.0441\n",
      "Epoch [1/1], Step [5400/7650], Loss: 0.1403\n",
      "Epoch [1/1], Step [5500/7650], Loss: 0.5183\n",
      "Epoch [1/1], Step [5600/7650], Loss: 0.3409\n",
      "Epoch [1/1], Step [5700/7650], Loss: 0.0261\n",
      "Epoch [1/1], Step [5800/7650], Loss: 0.0382\n",
      "Epoch [1/1], Step [5900/7650], Loss: 0.0198\n",
      "Epoch [1/1], Step [6000/7650], Loss: 0.0720\n",
      "Epoch [1/1], Step [6100/7650], Loss: 0.0516\n",
      "Epoch [1/1], Step [6200/7650], Loss: 0.0103\n",
      "Epoch [1/1], Step [6300/7650], Loss: 0.0070\n",
      "Epoch [1/1], Step [6400/7650], Loss: 0.0105\n",
      "Epoch [1/1], Step [6500/7650], Loss: 0.0153\n",
      "Epoch [1/1], Step [6600/7650], Loss: 0.0053\n",
      "Epoch [1/1], Step [6700/7650], Loss: 0.0127\n",
      "Epoch [1/1], Step [6800/7650], Loss: 0.0124\n",
      "Epoch [1/1], Step [6900/7650], Loss: 0.0061\n",
      "Epoch [1/1], Step [7000/7650], Loss: 0.0060\n",
      "Epoch [1/1], Step [7100/7650], Loss: 0.0037\n",
      "Epoch [1/1], Step [7200/7650], Loss: 0.0363\n",
      "Epoch [1/1], Step [7300/7650], Loss: 0.0054\n",
      "Epoch [1/1], Step [7400/7650], Loss: 0.3450\n",
      "Epoch [1/1], Step [7500/7650], Loss: 0.1540\n",
      "Epoch [1/1], Step [7600/7650], Loss: 0.2990\n",
      "Accuracy of the network on the test set: 98.74074074074075 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from model.AMCModel import AMCModel\n",
    "from data.dataset.OFDMDataset import OFDMDataset, get_dataloaders\n",
    "from torch.optim import Adam, RMSprop\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "LR = 0.0003\n",
    "BATCH_SIZE = 1\n",
    "SHUFFLE = True\n",
    "EPOCHS = 1\n",
    "\n",
    "dataset = OFDMDataset()\n",
    "trainloader, testloader = get_dataloaders(dataset=dataset, batch_size=BATCH_SIZE, shuffle=SHUFFLE)\n",
    "\n",
    "model = AMCModel()\n",
    "model = model.train()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(params=model.parameters(), lr=LR)\n",
    "\n",
    "n_total_steps = len(trainloader)\n",
    "losses = []\n",
    "predictions = []\n",
    "for epoch in range(EPOCHS):\n",
    "    model = model.train()\n",
    "    for i, (x, y) in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        scores = model(x)\n",
    "        loss = criterion(scores, torch.squeeze(y))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        predictions.append(torch.argmax(scores).item())\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{EPOCHS}], Step [{i+1}/{n_total_steps}], Loss: {np.mean(losses):.4f}')\n",
    "            losses.clear()\n",
    "\n",
    "    model = model.eval()\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        for x, y in testloader: \n",
    "            scores = model.forward(x)\n",
    "            predicted = torch.argmax(scores).item()\n",
    "            labels = torch.argmax(torch.squeeze(y)).item()\n",
    "            n_samples += y.size(0)\n",
    "            n_correct += predicted == labels\n",
    "\n",
    "        acc = 100.0 * n_correct / n_samples\n",
    "        print(f'Accuracy of the network on the test set: {acc} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
